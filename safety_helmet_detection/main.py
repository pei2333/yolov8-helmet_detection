#!/usr/bin/env python3
import os
import sys
import argparse
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent
sys.path.append(str(project_root))

def show_menu():
    print("\n" + "="*70)
    print("ğŸš§ è½»é‡åŒ–å®‰å…¨å¸½æ£€æµ‹ç³»ç»Ÿ")
    print("="*70)
    print("1. è®­ç»ƒåŸºçº¿YOLOv8æ¨¡å‹")
    print("2. è®­ç»ƒè½»é‡åŒ–æ”¹è¿›æ¨¡å‹")
    print("3. ğŸ”¥ å…¨é‡æ•°æ®è®­ç»ƒ (å®Œæ•´æ•°æ®é›†)")
    print("4. æ¨¡å‹æ€§èƒ½å¯¹æ¯”è¯„ä¼°")
    print("5. å®æ—¶æ£€æµ‹ (æ‘„åƒå¤´/è§†é¢‘)")
    print("6. æµ‹è¯•æ¨¡å—å¯¼å…¥")
    print("7. æ¨¡å‹æ¶æ„åˆ†æ")
    print("8. å®Œæ•´å¾®è°ƒæµ‹è¯• (é›†æˆæ‰€æœ‰æ¨¡å—)")
    print("9. æ¨¡å‹æ¨ç†åŸºå‡†æµ‹è¯•")
    print("0. é€€å‡º")
    print("="*70)

def select_dataset():
    print("\nğŸ“Š é€‰æ‹©è®­ç»ƒæ•°æ®é›†:")
    print("1. å­é›† (500å¼ å›¾åƒ) - å¿«é€ŸéªŒè¯")
    print("2. ä¸­ç­‰è§„æ¨¡ (1500å¼ å›¾åƒ) - å¹³è¡¡è®­ç»ƒ")
    print("3. å®Œæ•´æ•°æ®é›† (5000å¼ å›¾åƒ) - å®Œæ•´è®­ç»ƒ")
    
    while True:
        choice = input("è¯·é€‰æ‹©æ•°æ®é›†è§„æ¨¡ (1-3): ").strip()
        if choice == "1":
            return "subset", 500
        elif choice == "2":
            return "medium", 1500
        elif choice == "3":
            return "full", 5000
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")

def train_baseline():
    print("\nğŸ”„ è®­ç»ƒåŸºçº¿YOLOv8æ¨¡å‹")
    dataset_type, dataset_size = select_dataset()
    
    try:
        from models.baseline_trainer import BaselineTrainer
        trainer = BaselineTrainer(
            dataset_type=dataset_type,
            dataset_size=dataset_size
        )
        trainer.train()
    except Exception as e:
        print(f"âŒ åŸºçº¿æ¨¡å‹è®­ç»ƒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

def train_lightweight():
    print("\nğŸ”„ è®­ç»ƒè½»é‡åŒ–æ”¹è¿›æ¨¡å‹")
    dataset_type, dataset_size = select_dataset()
    
    try:
        from models.lightweight_trainer import LightweightTrainer
        trainer = LightweightTrainer(
            dataset_type=dataset_type,
            dataset_size=dataset_size
        )
        trainer.train()
    except Exception as e:
        print(f"âŒ è½»é‡åŒ–æ¨¡å‹è®­ç»ƒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

def test_modules():
    print("\nğŸ§ª æµ‹è¯•æ¨¡å—å¯¼å…¥...")
    
    try:
        print("æµ‹è¯•åŸºç¡€ä¾èµ–...")
        import torch
        import torchvision
        import ultralytics
        import cv2
        print(f"âœ… PyTorch: {torch.__version__}")
        print(f"âœ… Torchvision: {torchvision.__version__}")
        print(f"âœ… Ultralytics: {ultralytics.__version__}")
        print(f"âœ… OpenCV: {cv2.__version__}")
        
        print("\næµ‹è¯•è‡ªå®šä¹‰æ¨¡å—...")
        from modules.fasternet import FasterNetBlock, C2f_Fast
        from modules.fsdi import FSDI
        from modules.attention import A2_Attention, PAM_Attention
        from modules.losses import FocalerCIOULoss, EnhancedFocalLoss
        print("âœ… æ‰€æœ‰è‡ªå®šä¹‰æ¨¡å—å¯¼å…¥æˆåŠŸ")
        
        print("\næµ‹è¯•æ¨¡å—åŠŸèƒ½...")
        import torch
        
        # æµ‹è¯•FasterNet
        faster_block = FasterNetBlock(64, 64)
        test_input = torch.randn(1, 64, 32, 32)
        output = faster_block(test_input)
        print(f"âœ… FasterNet: {test_input.shape} -> {output.shape}")
        
        # æµ‹è¯•FSDI
        fsdi = FSDI([256, 512, 1024], 256)
        features = [
            torch.randn(1, 256, 32, 32),
            torch.randn(1, 512, 16, 16),
            torch.randn(1, 1024, 8, 8)
        ]
        fsdi_out = fsdi(features)
        print(f"âœ… FSDI: å¤šå°ºåº¦èåˆæˆåŠŸï¼Œè¾“å‡ºæ•°é‡: {len(fsdi_out)}")
        
        # æµ‹è¯•æ³¨æ„åŠ›
        attention = A2_Attention(256)
        att_input = torch.randn(1, 256, 32, 32)
        att_output = attention(att_input)
        print(f"âœ… A2_Attention: {att_input.shape} -> {att_output.shape}")
        
        print("\nğŸ‰ æ‰€æœ‰æ¨¡å—æµ‹è¯•é€šè¿‡ï¼")
        
    except Exception as e:
        print(f"âŒ æ¨¡å—æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

def analyze_models():
    print("\nğŸ“Š æ¨¡å‹æ¶æ„åˆ†æ...")
    
    try:
        import torch
        from modules.fasternet import FasterNetBlock, C2f_Fast
        from modules.fsdi import FSDI
        from modules.attention import A2_Attention
        
        print("=== æ¨¡å‹å‚æ•°é‡åˆ†æ ===")
        
        # FasterNet Block
        faster_block = FasterNetBlock(256, 256)
        faster_params = sum(p.numel() for p in faster_block.parameters())
        print(f"FasterNet Block (256->256): {faster_params:,} å‚æ•°")
        
        # C2f_Fast
        c2f_fast = C2f_Fast(256, 256, n=3)
        c2f_params = sum(p.numel() for p in c2f_fast.parameters())
        print(f"C2f_Fast (n=3): {c2f_params:,} å‚æ•°")
        
        # FSDI
        fsdi = FSDI([256, 512, 1024], 256)
        fsdi_params = sum(p.numel() for p in fsdi.parameters())
        print(f"FSDI èåˆæ¨¡å—: {fsdi_params:,} å‚æ•°")
        
        # A2 Attention
        attention = A2_Attention(256)
        att_params = sum(p.numel() for p in attention.parameters())
        print(f"A2 æ³¨æ„åŠ›: {att_params:,} å‚æ•°")
        
        print(f"\næ€»è½»é‡åŒ–æ¨¡å—å‚æ•°: {faster_params + c2f_params + fsdi_params + att_params:,}")
        
        print("\n=== æ¨ç†æ€§èƒ½æµ‹è¯• ===")
        import time
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"æµ‹è¯•è®¾å¤‡: {device}")
        
        test_input = torch.randn(1, 256, 64, 64).to(device)
        faster_block = faster_block.to(device)
        
        # é¢„çƒ­
        for _ in range(10):
            _ = faster_block(test_input)
        
        # æµ‹è¯•æ¨ç†æ—¶é—´
        start_time = time.time()
        for _ in range(100):
            with torch.no_grad():
                _ = faster_block(test_input)
        end_time = time.time()
        
        avg_time = (end_time - start_time) / 100 * 1000  # ms
        print(f"FasterNetå¹³å‡æ¨ç†æ—¶é—´: {avg_time:.2f} ms")
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹åˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

def train_full_dataset():
    """å…¨é‡æ•°æ®è®­ç»ƒ - ä½¿ç”¨å®Œæ•´æ•°æ®é›†è¿›è¡Œé«˜è´¨é‡è®­ç»ƒ"""
    print("\nğŸ”¥ å…¨é‡æ•°æ®è®­ç»ƒ")
    print("=" * 50)
    print("ğŸ“‹ é…ç½®ä¿¡æ¯:")
    print("  - æ•°æ®é›†: å®Œæ•´æ•°æ®é›† (5000+ å¼ å›¾åƒ)")
    print("  - æ¨¡å‹: è½»é‡åŒ–æ”¹è¿›æ¨¡å‹")
    print("  - è®­ç»ƒè½®æ•°: 200 epochs")
    print("  - æ‰¹æ¬¡å¤§å°: 16 (GPU) / 4 (CPU)")
    print("  - éªŒè¯é¢‘ç‡: æ¯10è½®éªŒè¯ä¸€æ¬¡")
    print("  - æ—©åœ: è€å¿ƒåº¦50è½®")
    print("=" * 50)
    
    confirm = input("âš ï¸  å…¨é‡è®­ç»ƒéœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œç¡®è®¤å¼€å§‹ï¼Ÿ(y/N): ").strip().lower()
    if confirm not in ['y', 'yes']:
        print("âŒ ç”¨æˆ·å–æ¶ˆè®­ç»ƒ")
        return
    
    try:
        import torch
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        batch_size = 16 if torch.cuda.is_available() else 4
        
        print(f"\nğŸš€ å¼€å§‹å…¨é‡æ•°æ®è®­ç»ƒ...")
        print(f"   è®¾å¤‡: {device}")
        print(f"   æ‰¹æ¬¡å¤§å°: {batch_size}")
        
        from models.lightweight_trainer import LightweightTrainer
        trainer = LightweightTrainer(
            dataset_type="full",
            dataset_size=5000,
            epochs=200,
            batch_size=batch_size,
            patience=50,
            val_interval=10
        )
        
        print("ğŸ“Š å¼€å§‹è®­ç»ƒï¼Œè¿™å¯èƒ½éœ€è¦æ•°å°æ—¶...")
        results = trainer.train()
        
        print(f"\nğŸ‰ å…¨é‡è®­ç»ƒå®Œæˆï¼")
        print(f"   æœ€ä½³mAP50: {results.get('best_map50', 'N/A')}")
        print(f"   æœ€ä½³mAP75: {results.get('best_map75', 'N/A')}")
        print(f"   æ¨¡å‹ä¿å­˜è·¯å¾„: {results.get('save_dir', 'N/A')}")
        
    except Exception as e:
        print(f"âŒ å…¨é‡è®­ç»ƒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

def evaluate_models():
    """æ¨¡å‹æ€§èƒ½å¯¹æ¯”è¯„ä¼°"""
    print("\nğŸ“Š æ¨¡å‹æ€§èƒ½å¯¹æ¯”è¯„ä¼°")
    print("=" * 50)
    
    # æ£€æŸ¥å¯ç”¨æ¨¡å‹
    available_models = []
    model_paths = [
        "runs/detect/baseline/weights/best.pt",
        "runs/detect/lightweight/weights/best.pt",
        "runs/detect/full_training/weights/best.pt"
    ]
    model_names = ["åŸºçº¿æ¨¡å‹", "è½»é‡åŒ–æ¨¡å‹", "å…¨é‡è®­ç»ƒæ¨¡å‹"]
    
    for path, name in zip(model_paths, model_names):
        if os.path.exists(path):
            available_models.append((name, path))
    
    if len(available_models) < 2:
        print("âŒ éœ€è¦è‡³å°‘2ä¸ªè®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œå¯¹æ¯”")
        print("   è¯·å…ˆè¿è¡Œè®­ç»ƒå‘½ä»¤ç”Ÿæˆæ¨¡å‹")
        return
    
    print("ğŸ“‹ å¯ç”¨æ¨¡å‹:")
    for i, (name, path) in enumerate(available_models):
        print(f"   {i+1}. {name}: {path}")
    
    try:
        from ultralytics import YOLO
        import time
        
        print("\nğŸ”„ å¼€å§‹æ€§èƒ½è¯„ä¼°...")
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        test_image_path = "test_image.jpg"
        if not os.path.exists(test_image_path):
            import cv2
            import numpy as np
            test_img = np.random.randint(0, 255, (640, 640, 3), dtype=np.uint8)
            cv2.imwrite(test_image_path, test_img)
        
        results = {}
        for name, path in available_models:
            print(f"\næµ‹è¯• {name}...")
            model = YOLO(path)
            
            # å‚æ•°é‡ç»Ÿè®¡
            total_params = sum(p.numel() for p in model.model.parameters())
            
            # æ¨ç†é€Ÿåº¦æµ‹è¯•
            warmup_runs = 10
            test_runs = 50
            
            # é¢„çƒ­
            for _ in range(warmup_runs):
                _ = model(test_image_path, verbose=False)
            
            # æµ‹è¯•æ¨ç†æ—¶é—´
            start_time = time.time()
            for _ in range(test_runs):
                _ = model(test_image_path, verbose=False)
            end_time = time.time()
            
            avg_time = (end_time - start_time) / test_runs * 1000  # ms
            fps = 1000 / avg_time
            
            results[name] = {
                'params': total_params,
                'inference_time': avg_time,
                'fps': fps,
                'model_size': os.path.getsize(path) / (1024 * 1024)  # MB
            }
        
        # æ‰“å°å¯¹æ¯”ç»“æœ
        print("\nğŸ“Š æ€§èƒ½å¯¹æ¯”ç»“æœ:")
        print("=" * 80)
        print(f"{'æ¨¡å‹':<15} {'å‚æ•°é‡':<12} {'æ¨ç†æ—¶é—´(ms)':<12} {'FPS':<8} {'æ¨¡å‹å¤§å°(MB)':<12}")
        print("-" * 80)
        
        for name, metrics in results.items():
            print(f"{name:<15} {metrics['params']:>10,} {metrics['inference_time']:>10.2f} "
                  f"{metrics['fps']:>6.1f} {metrics['model_size']:>10.1f}")
        
        # æ¸…ç†æµ‹è¯•æ–‡ä»¶
        if os.path.exists(test_image_path):
            os.remove(test_image_path)
            
    except Exception as e:
        print(f"âŒ æ¨¡å‹è¯„ä¼°å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

def real_time_detection():
    """å®æ—¶æ£€æµ‹åŠŸèƒ½"""
    print("\nğŸ“¹ å®æ—¶æ£€æµ‹")
    print("=" * 50)
    print("1. æ‘„åƒå¤´æ£€æµ‹")
    print("2. è§†é¢‘æ–‡ä»¶æ£€æµ‹")
    print("3. å›¾åƒæ£€æµ‹")
    
    choice = input("è¯·é€‰æ‹©æ£€æµ‹æ¨¡å¼ (1-3): ").strip()
    
    # é€‰æ‹©æ¨¡å‹
    model_path = None
    if os.path.exists("runs/detect/lightweight/weights/best.pt"):
        model_path = "runs/detect/lightweight/weights/best.pt"
        print("ğŸ¤– ä½¿ç”¨è½»é‡åŒ–æ¨¡å‹")
    elif os.path.exists("runs/detect/baseline/weights/best.pt"):
        model_path = "runs/detect/baseline/weights/best.pt"
        print("ğŸ¤– ä½¿ç”¨åŸºçº¿æ¨¡å‹")
    else:
        print("âŒ æœªæ‰¾åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œè¯·å…ˆè¿è¡Œè®­ç»ƒå‘½ä»¤")
        return
    
    try:
        from ultralytics import YOLO
        model = YOLO(model_path)
        
        if choice == "1":
            print("ğŸ“· å¯åŠ¨æ‘„åƒå¤´æ£€æµ‹...")
            print("æŒ‰ 'q' é”®é€€å‡º")
            model.predict(source=0, show=True, save=False, stream=True)
            
        elif choice == "2":
            video_path = input("è¯·è¾“å…¥è§†é¢‘æ–‡ä»¶è·¯å¾„: ").strip()
            if not os.path.exists(video_path):
                print("âŒ è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨")
                return
            print(f"ğŸ“¹ æ£€æµ‹è§†é¢‘: {video_path}")
            model.predict(source=video_path, show=True, save=True)
            
        elif choice == "3":
            image_path = input("è¯·è¾“å…¥å›¾åƒæ–‡ä»¶è·¯å¾„: ").strip()
            if not os.path.exists(image_path):
                print("âŒ å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨")
                return
            print(f"ğŸ–¼ï¸  æ£€æµ‹å›¾åƒ: {image_path}")
            results = model.predict(source=image_path, show=True, save=True)
            
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©")
            
    except Exception as e:
        print(f"âŒ å®æ—¶æ£€æµ‹å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

def benchmark_model():
    """æ¨¡å‹æ¨ç†åŸºå‡†æµ‹è¯•"""
    print("\nâš¡ æ¨¡å‹æ¨ç†åŸºå‡†æµ‹è¯•")
    print("=" * 50)
    
    # é€‰æ‹©æ¨¡å‹
    available_models = []
    model_paths = [
        ("åŸºçº¿æ¨¡å‹", "runs/detect/baseline/weights/best.pt"),
        ("è½»é‡åŒ–æ¨¡å‹", "runs/detect/lightweight/weights/best.pt"),
        ("å…¨é‡è®­ç»ƒæ¨¡å‹", "runs/detect/full_training/weights/best.pt")
    ]
    
    for name, path in model_paths:
        if os.path.exists(path):
            available_models.append((name, path))
    
    if not available_models:
        print("âŒ æœªæ‰¾åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹")
        return
    
    print("å¯ç”¨æ¨¡å‹:")
    for i, (name, _) in enumerate(available_models):
        print(f"  {i+1}. {name}")
    
    try:
        choice = int(input("è¯·é€‰æ‹©æ¨¡å‹ (1-{}): ".format(len(available_models)))) - 1
        if choice < 0 or choice >= len(available_models):
            print("âŒ æ— æ•ˆé€‰æ‹©")
            return
        
        model_name, model_path = available_models[choice]
        
        from ultralytics import YOLO
        import torch
        import time
        import numpy as np
        
        print(f"\nğŸ”„ åŠ è½½æ¨¡å‹: {model_name}")
        model = YOLO(model_path)
        
        # åˆ›å»ºä¸åŒå°ºå¯¸çš„æµ‹è¯•æ•°æ®
        test_sizes = [320, 416, 640, 1024]
        batch_sizes = [1, 4, 8] if torch.cuda.is_available() else [1, 2]
        
        print("\nğŸ“Š åŸºå‡†æµ‹è¯•ç»“æœ:")
        print("=" * 80)
        print(f"{'å›¾åƒå°ºå¯¸':<10} {'æ‰¹æ¬¡å¤§å°':<8} {'æ¨ç†æ—¶é—´(ms)':<12} {'FPS':<8} {'å†…å­˜ä½¿ç”¨(MB)':<12}")
        print("-" * 80)
        
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        for img_size in test_sizes:
            for batch_size in batch_sizes:
                try:
                    # åˆ›å»ºæµ‹è¯•æ•°æ®
                    test_input = torch.randn(batch_size, 3, img_size, img_size).to(device)
                    
                    # é¢„çƒ­
                    for _ in range(10):
                        with torch.no_grad():
                            _ = model.model(test_input)
                    
                    # æµ‹è¯•æ¨ç†æ—¶é—´
                    torch.cuda.synchronize() if torch.cuda.is_available() else None
                    start_time = time.time()
                    
                    test_runs = 100
                    for _ in range(test_runs):
                        with torch.no_grad():
                            _ = model.model(test_input)
                    
                    torch.cuda.synchronize() if torch.cuda.is_available() else None
                    end_time = time.time()
                    
                    avg_time = (end_time - start_time) / test_runs * 1000  # ms
                    fps = 1000 / (avg_time / batch_size)
                    
                    # å†…å­˜ä½¿ç”¨
                    if torch.cuda.is_available():
                        memory_used = torch.cuda.max_memory_allocated() / (1024**2)  # MB
                        torch.cuda.reset_peak_memory_stats()
                    else:
                        memory_used = 0
                    
                    print(f"{img_size:<10} {batch_size:<8} {avg_time:<12.2f} {fps:<8.1f} {memory_used:<12.1f}")
                    
                except Exception as e:
                    print(f"{img_size:<10} {batch_size:<8} {'å¤±è´¥':<12} {'N/A':<8} {'N/A':<12}")
        
    except Exception as e:
        print(f"âŒ åŸºå‡†æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

def run_full_training_test():
    print("\nğŸ”¬ è¿è¡Œå®Œæ•´å¾®è°ƒæµ‹è¯•...")
    try:
        from full_training_test import FullTrainingTester
        tester = FullTrainingTester()
        tester.run_full_test()
    except Exception as e:
        print(f"âŒ å®Œæ•´å¾®è°ƒæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

def main():
    parser = argparse.ArgumentParser(description="è½»é‡åŒ–å®‰å…¨å¸½æ£€æµ‹ç³»ç»Ÿ")
    parser.add_argument("--mode", choices=[
        "cmd", "baseline", "lightweight", "full", "evaluate", "detect", 
        "test", "analyze", "full_test", "benchmark"
    ], help="ç›´æ¥è¿è¡Œæ¨¡å¼")
    parser.add_argument("--dataset", choices=["subset", "medium", "full"], 
                       default="medium", help="æ•°æ®é›†è§„æ¨¡")
    parser.add_argument("--data", type=str, help="æ•°æ®é›†é…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--epochs", type=int, default=100, help="è®­ç»ƒè½®æ•°")
    parser.add_argument("--batch-size", type=int, default=16, help="æ‰¹æ¬¡å¤§å°")
    parser.add_argument("--source", type=str, help="æ£€æµ‹æº (æ‘„åƒå¤´/è§†é¢‘/å›¾åƒ)")
    parser.add_argument("--model1", type=str, help="å¯¹æ¯”è¯„ä¼°çš„ç¬¬ä¸€ä¸ªæ¨¡å‹")
    parser.add_argument("--model2", type=str, help="å¯¹æ¯”è¯„ä¼°çš„ç¬¬äºŒä¸ªæ¨¡å‹")
    parser.add_argument("--model", type=str, help="åŸºå‡†æµ‹è¯•çš„æ¨¡å‹è·¯å¾„")
    parser.add_argument("--test-modules", action="store_true", help="æµ‹è¯•æ‰€æœ‰æ¨¡å—")
    parser.add_argument("--analyze-architecture", action="store_true", help="åˆ†ææ¨¡å‹æ¶æ„")
    parser.add_argument("--train-baseline", action="store_true", help="è®­ç»ƒåŸºçº¿æ¨¡å‹")
    parser.add_argument("--train-lightweight", action="store_true", help="è®­ç»ƒè½»é‡åŒ–æ¨¡å‹")
    parser.add_argument("--train-full", action="store_true", help="å…¨é‡æ•°æ®è®­ç»ƒ")
    
    args = parser.parse_args()
    
    # å‘½ä»¤è¡Œå¿«æ·æ“ä½œ
    if args.test_modules:
        test_modules()
        return
    elif args.analyze_architecture:
        analyze_models()
        return
    elif args.train_baseline:
        train_baseline()
        return
    elif args.train_lightweight:
        train_lightweight()
        return
    elif args.train_full:
        train_full_dataset()
        return
    
    # æ¨¡å¼é€‰æ‹©
    if args.mode:
        if args.mode == "cmd":
            pass  # ç»§ç»­åˆ°äº¤äº’å¼èœå•
        elif args.mode == "baseline":
            train_baseline()
        elif args.mode == "lightweight":
            train_lightweight()
        elif args.mode == "full":
            train_full_dataset()
        elif args.mode == "evaluate":
            evaluate_models()
        elif args.mode == "detect":
            real_time_detection()
        elif args.mode == "test":
            test_modules()
        elif args.mode == "analyze":
            analyze_models()
        elif args.mode == "full_test":
            run_full_training_test()
        elif args.mode == "benchmark":
            benchmark_model()
        
        if args.mode != "cmd":
            return
    
    # äº¤äº’å¼èœå•
    while True:
        show_menu()
        
        try:
            choice = input("\nè¯·é€‰æ‹©æ“ä½œ (0-9): ").strip()
            
            if choice == "0":
                print("æ„Ÿè°¢ä½¿ç”¨è½»é‡åŒ–å®‰å…¨å¸½æ£€æµ‹ç³»ç»Ÿï¼")
                break
            elif choice == "1":
                train_baseline()
            elif choice == "2":
                train_lightweight()
            elif choice == "3":
                train_full_dataset()
            elif choice == "4":
                evaluate_models()
            elif choice == "5":
                real_time_detection()
            elif choice == "6":
                test_modules()
            elif choice == "7":
                analyze_models()
            elif choice == "8":
                run_full_training_test()
            elif choice == "9":
                benchmark_model()
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")
                
        except KeyboardInterrupt:
            print("\n\nç”¨æˆ·ä¸­æ–­ï¼Œé€€å‡ºç¨‹åº")
            break
        except Exception as e:
            print(f"âŒ æ‰§è¡Œé”™è¯¯: {e}")
            
        input("\næŒ‰å›è½¦é”®ç»§ç»­...")

if __name__ == "__main__":
    main() 