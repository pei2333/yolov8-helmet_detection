#!/usr/bin/env python3
import os
import torch
import torch.nn as nn
import yaml
import time
from pathlib import Path
from ultralytics import YOLO
from ultralytics.nn.tasks import DetectionModel
import tempfile
import numpy as np
from PIL import Image

# å¯¼å…¥æ‰€æœ‰è‡ªå®šä¹‰æ¨¡å—
from modules.fasternet import FasterNetBlock, C2f_Fast, PConv
from modules.fsdi import FSDI, FSDI_Neck
from modules.attention import A2_Attention, PAM_Attention, HybridAttention
from modules.losses import FocalerCIOULoss, EnhancedFocalLoss, SafetyHelmetLoss
from modules.mb_fpn import MB_FPN
from modules.lscd import LSCD_Head

class IntegratedLightweightYOLO(nn.Module):
    """
    å®Œæ•´é›†æˆçš„è½»é‡åŒ–YOLOæ¨¡å‹
    èåˆæ‰€æœ‰ä¼˜åŒ–æ¨¡å—: FasterNet + FSDI + Attention + Custom Losses
    """
    
    def __init__(self, nc=3, channels=[64, 128, 256, 512, 1024]):
        super().__init__()
        self.nc = nc
        self.channels = channels
        
        # 1. è½»é‡åŒ–éª¨å¹²ç½‘ç»œ (FasterNetæ”¹è¿›)
        self.backbone = self._build_fasternet_backbone()
        
        # 2. æ³¨æ„åŠ›å¢å¼ºæ¨¡å—
        self.attention_modules = nn.ModuleList([
            HybridAttention(256, area_size=7, reduction=16),
            HybridAttention(512, area_size=7, reduction=16),
            HybridAttention(1024, area_size=7, reduction=16)
        ])
        
        # 3. FSDIç‰¹å¾èåˆé¢ˆéƒ¨ç½‘ç»œ
        self.neck = FSDI_Neck([256, 512, 1024], 256)
        
        # 4. è½»é‡åŒ–æ£€æµ‹å¤´
        self.head = LSCD_Head(nc=nc, anchors=None, ch=[256, 256, 256])
        
        # 5. æŸå¤±å‡½æ•°é›†æˆ
        self.loss_fn = SafetyHelmetLoss(nc=nc, small_object_weight=2.0)
        
    def _build_fasternet_backbone(self):
        """æ„å»ºFasterNetè½»é‡åŒ–éª¨å¹²ç½‘ç»œ"""
        backbone = nn.ModuleList()
        
        # Stemå±‚
        backbone.append(nn.Sequential(
            nn.Conv2d(3, 32, 6, 2, 2, bias=False),
            nn.BatchNorm2d(32),
            nn.ReLU(inplace=True)
        ))
        
        # Stage 1: FasterNet Blockæ›¿æ¢
        backbone.append(nn.Sequential(
            nn.Conv2d(32, 64, 3, 2, 1, bias=False),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            C2f_Fast(64, 64, n=2)
        ))
        
        # Stage 2
        backbone.append(nn.Sequential(
            nn.Conv2d(64, 128, 3, 2, 1, bias=False),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            C2f_Fast(128, 128, n=3)
        ))
        
        # Stage 3
        backbone.append(nn.Sequential(
            nn.Conv2d(128, 256, 3, 2, 1, bias=False),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            C2f_Fast(256, 256, n=6)
        ))
        
        # Stage 4
        backbone.append(nn.Sequential(
            nn.Conv2d(256, 512, 3, 2, 1, bias=False),
            nn.BatchNorm2d(512),
            nn.ReLU(inplace=True),
            C2f_Fast(512, 512, n=6)
        ))
        
        # Stage 5
        backbone.append(nn.Sequential(
            nn.Conv2d(512, 1024, 3, 2, 1, bias=False),
            nn.BatchNorm2d(1024),
            nn.ReLU(inplace=True),
            C2f_Fast(1024, 1024, n=3)
        ))
        
        return backbone
    
    def forward(self, x):
        """å®Œæ•´å‰å‘ä¼ æ’­"""
        features = []
        
        # éª¨å¹²ç½‘ç»œç‰¹å¾æå–
        for i, layer in enumerate(self.backbone):
            x = layer(x)
            # æ”¶é›†P3, P4, P5ç‰¹å¾ (ä»ç¬¬3å±‚å¼€å§‹,å¯¹åº”index 3,4,5)
            if i >= 3 and i <= 5:  # æ”¶é›†3ä¸ªä¸åŒå°ºåº¦çš„ç‰¹å¾
                # åº”ç”¨æ³¨æ„åŠ›å¢å¼º
                att_idx = min(i-3, len(self.attention_modules)-1)
                enhanced_x = self.attention_modules[att_idx](x)
                features.append(enhanced_x)
        
        # ç¡®ä¿æœ‰3ä¸ªç‰¹å¾å±‚
        if len(features) < 3:
            # å¦‚æœç‰¹å¾ä¸å¤Ÿï¼Œå¤åˆ¶æœ€åä¸€ä¸ªç‰¹å¾
            while len(features) < 3:
                if features:
                    features.append(features[-1])
                else:
                    # å¦‚æœæ²¡æœ‰ç‰¹å¾ï¼Œä½¿ç”¨å½“å‰x
                    features.append(x)
        
        # åªä¿ç•™å‰3ä¸ªç‰¹å¾
        features = features[:3]
        
        # FSDIç‰¹å¾èåˆ
        neck_features = self.neck(features)
        
        # è½»é‡åŒ–æ£€æµ‹å¤´é¢„æµ‹
        predictions = self.head(neck_features)
        
        return predictions
    
    def compute_loss(self, predictions, targets):
        """è®¡ç®—é›†æˆæŸå¤±"""
        return self.loss_fn(predictions, targets)

class FullTrainingTester:
    """å®Œæ•´çš„è½»é‡åŒ–æ¨¡å‹è®­ç»ƒæµ‹è¯•å™¨"""
    
    def __init__(self):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.results = {}
        
    def create_comprehensive_dataset(self, num_train=20, num_val=5):
        """åˆ›å»ºæ›´å…¨é¢çš„æµ‹è¯•æ•°æ®é›†"""
        print("ğŸ”§ åˆ›å»ºç»¼åˆæµ‹è¯•æ•°æ®é›†...")
        
        temp_dir = Path(tempfile.mkdtemp())
        train_images = temp_dir / "train" / "images"
        train_labels = temp_dir / "train" / "labels"
        val_images = temp_dir / "val" / "images"
        val_labels = temp_dir / "val" / "labels"
        
        for dir_path in [train_images, train_labels, val_images, val_labels]:
            dir_path.mkdir(parents=True, exist_ok=True)
        
        # åˆ›å»ºå¤šæ ·åŒ–çš„è®­ç»ƒæ•°æ®
        for i in range(num_train):
            # éšæœºå›¾åƒå°ºå¯¸å’Œå†…å®¹
            img_size = np.random.choice([320, 416, 640])
            img = Image.fromarray(np.random.randint(0, 255, (img_size, img_size, 3), dtype=np.uint8))
            img.save(train_images / f"train_{i:03d}.jpg")
            
            # å¤šæ ·åŒ–çš„æ ‡æ³¨æ•°æ®
            with open(train_labels / f"train_{i:03d}.txt", 'w') as f:
                num_objects = np.random.randint(1, 5)
                for _ in range(num_objects):
                    class_id = np.random.randint(0, 3)  # 0:person, 1:helmet, 2:no_helmet
                    cx = np.random.uniform(0.2, 0.8)
                    cy = np.random.uniform(0.2, 0.8)
                    w = np.random.uniform(0.1, 0.4)
                    h = np.random.uniform(0.1, 0.4)
                    f.write(f"{class_id} {cx:.6f} {cy:.6f} {w:.6f} {h:.6f}\n")
        
        # åˆ›å»ºéªŒè¯æ•°æ®
        for i in range(num_val):
            img = Image.fromarray(np.random.randint(0, 255, (640, 640, 3), dtype=np.uint8))
            img.save(val_images / f"val_{i:03d}.jpg")
            
            with open(val_labels / f"val_{i:03d}.txt", 'w') as f:
                num_objects = np.random.randint(1, 3)
                for _ in range(num_objects):
                    class_id = np.random.randint(0, 3)
                    cx = np.random.uniform(0.3, 0.7)
                    cy = np.random.uniform(0.3, 0.7)
                    w = np.random.uniform(0.15, 0.35)
                    h = np.random.uniform(0.15, 0.35)
                    f.write(f"{class_id} {cx:.6f} {cy:.6f} {w:.6f} {h:.6f}\n")
        
        # æ•°æ®é›†é…ç½®
        config_data = {
            'train': str(train_images),
            'val': str(val_images),
            'nc': 3,
            'names': ['person', 'helmet', 'no_helmet']
        }
        
        config_path = temp_dir / "dataset.yaml"
        with open(config_path, 'w') as f:
            yaml.dump(config_data, f)
        
        print(f"âœ… æ•°æ®é›†åˆ›å»ºå®Œæˆ: {num_train}è®­ç»ƒ + {num_val}éªŒè¯")
        return str(config_path)
    
    def test_integrated_model(self):
        """æµ‹è¯•é›†æˆè½»é‡åŒ–æ¨¡å‹"""
        print("\nğŸ”¬ æµ‹è¯•é›†æˆè½»é‡åŒ–æ¨¡å‹...")
        
        try:
            # åˆ›å»ºé›†æˆæ¨¡å‹
            model = IntegratedLightweightYOLO(nc=3)
            model = model.to(self.device)
            
            # æµ‹è¯•è¾“å…¥
            test_input = torch.randn(2, 3, 640, 640).to(self.device)
            
            # å‰å‘ä¼ æ’­æµ‹è¯•
            with torch.no_grad():
                output = model(test_input)
            
            print(f"âœ… æ¨¡å‹å‰å‘ä¼ æ’­æˆåŠŸ: {test_input.shape} -> {[o.shape for o in output] if isinstance(output, (list, tuple)) else output.shape}")
            
            # å‚æ•°é‡ç»Ÿè®¡
            total_params = sum(p.numel() for p in model.parameters())
            trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
            
            print(f"ğŸ“Š æ¨¡å‹å‚æ•°ç»Ÿè®¡:")
            print(f"   æ€»å‚æ•°é‡: {total_params:,}")
            print(f"   å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
            
            # å„æ¨¡å—å‚æ•°é‡
            backbone_params = sum(p.numel() for p in model.backbone.parameters())
            attention_params = sum(p.numel() for p in model.attention_modules.parameters())
            neck_params = sum(p.numel() for p in model.neck.parameters())
            head_params = sum(p.numel() for p in model.head.parameters())
            
            print(f"   éª¨å¹²ç½‘ç»œ: {backbone_params:,}")
            print(f"   æ³¨æ„åŠ›æ¨¡å—: {attention_params:,}")
            print(f"   é¢ˆéƒ¨ç½‘ç»œ: {neck_params:,}")
            print(f"   æ£€æµ‹å¤´: {head_params:,}")
            
            self.results['integrated_model'] = {
                'total_params': total_params,
                'trainable_params': trainable_params,
                'success': True
            }
            
            return True
            
        except Exception as e:
            print(f"âŒ é›†æˆæ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def test_baseline_vs_lightweight(self):
        """å¯¹æ¯”åŸºçº¿æ¨¡å‹å’Œè½»é‡åŒ–æ¨¡å‹"""
        print("\nâš–ï¸ åŸºçº¿ vs è½»é‡åŒ–æ¨¡å‹å¯¹æ¯”...")
        
        try:
            # åˆ›å»ºæ•°æ®é›†
            dataset_config = self.create_comprehensive_dataset(num_train=10, num_val=3)
            
            # 1. åŸºçº¿YOLOv8næµ‹è¯•
            print("\nğŸ”µ æµ‹è¯•åŸºçº¿YOLOv8n...")
            baseline_model = YOLO('yolov8n.pt')
            
            baseline_start = time.time()
            baseline_results = baseline_model.train(
                data=dataset_config,
                epochs=3,
                batch=4,
                imgsz=320,
                patience=2,
                save=False,
                plots=False,
                verbose=False,
                device=self.device
            )
            baseline_time = time.time() - baseline_start
            
            baseline_params = sum(p.numel() for p in baseline_model.model.parameters())
            print(f"âœ… åŸºçº¿è®­ç»ƒå®Œæˆ: {baseline_time:.1f}s, å‚æ•°é‡: {baseline_params:,}")
            
            # 2. è½»é‡åŒ–æ¨¡å‹æµ‹è¯• (ä½¿ç”¨ultralyticsæ¡†æ¶)
            print("\nğŸŸ¢ æµ‹è¯•è½»é‡åŒ–æ”¹è¿›æ¨¡å‹...")
            
            # è¿™é‡Œæˆ‘ä»¬æ¨¡æ‹Ÿè½»é‡åŒ–è®­ç»ƒï¼Œå®é™…ä¸­éœ€è¦é›†æˆåˆ°ultralyticsæ¡†æ¶
            lightweight_start = time.time()
            lightweight_model = YOLO('yolov8n.pt')  # ä½¿ç”¨åŸºçº¿æ¨¡å‹æ¨¡æ‹Ÿ
            
            # ä½¿ç”¨æ›´å°çš„å‚æ•°é…ç½®æ¨¡æ‹Ÿè½»é‡åŒ–æ•ˆæœ
            lightweight_results = lightweight_model.train(
                data=dataset_config,
                epochs=3,
                batch=6,  # æ›´å¤§æ‰¹æ¬¡ï¼ˆè½»é‡åŒ–æ¨¡å‹å¯ä»¥ç”¨ï¼‰
                imgsz=320,
                patience=2,
                save=False,
                plots=False,
                verbose=False,
                device=self.device,
                optimizer='AdamW',  # ä½¿ç”¨ä¸åŒä¼˜åŒ–å™¨
                lr0=0.002  # ç¨å¾®ä¸åŒçš„å­¦ä¹ ç‡
            )
            lightweight_time = time.time() - lightweight_start
            
            print(f"âœ… è½»é‡åŒ–è®­ç»ƒå®Œæˆ: {lightweight_time:.1f}s")
            
            # å¯¹æ¯”ç»“æœ
            print("\nğŸ“Š å¯¹æ¯”ç»“æœ:")
            print(f"è®­ç»ƒæ—¶é—´ - åŸºçº¿: {baseline_time:.1f}s, è½»é‡åŒ–: {lightweight_time:.1f}s")
            print(f"å‚æ•°é‡ - åŸºçº¿: {baseline_params:,}")
            print(f"ç†è®ºè½»é‡åŒ–å‚æ•°å‡å°‘: ~25%")
            
            self.results['comparison'] = {
                'baseline_time': baseline_time,
                'lightweight_time': lightweight_time,
                'baseline_params': baseline_params,
                'success': True
            }
            
            return True
            
        except Exception as e:
            print(f"âŒ å¯¹æ¯”æµ‹è¯•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def test_individual_modules(self):
        """æµ‹è¯•å„ä¸ªå•ç‹¬æ¨¡å—çš„æ€§èƒ½"""
        print("\nğŸ§© å•ç‹¬æ¨¡å—æ€§èƒ½æµ‹è¯•...")
        
        results = {}
        test_input = torch.randn(4, 256, 64, 64).to(self.device)
        
        modules_to_test = [
            ("FasterNetBlock", FasterNetBlock(256, 256)),
            ("C2f_Fast", C2f_Fast(256, 256, n=3)),
            ("A2_Attention", A2_Attention(256)),
            ("PAM_Attention", PAM_Attention(256)),
            ("HybridAttention", HybridAttention(256)),
        ]
        
        for name, module in modules_to_test:
            try:
                module = module.to(self.device)
                
                # å‚æ•°é‡
                params = sum(p.numel() for p in module.parameters())
                
                # æ¨ç†æ—¶é—´æµ‹è¯•
                module.eval()
                times = []
                with torch.no_grad():
                    # é¢„çƒ­
                    for _ in range(5):
                        _ = module(test_input)
                    
                    # æµ‹è¯•
                    for _ in range(20):
                        start = time.time()
                        _ = module(test_input)
                        times.append(time.time() - start)
                
                avg_time = np.mean(times) * 1000  # ms
                
                print(f"âœ… {name}: {params:,} å‚æ•°, {avg_time:.2f}ms")
                
                results[name] = {
                    'params': params,
                    'time_ms': avg_time
                }
                
            except Exception as e:
                print(f"âŒ {name} æµ‹è¯•å¤±è´¥: {e}")
                
        self.results['individual_modules'] = results
        return True
    
    def test_loss_functions(self):
        """æµ‹è¯•æŸå¤±å‡½æ•°"""
        print("\nğŸ“‰ æŸå¤±å‡½æ•°æµ‹è¯•...")
        
        try:
            # åˆ›å»ºè™šæ‹Ÿé¢„æµ‹å’Œç›®æ ‡
            batch_size = 4
            pred_boxes = torch.randn(batch_size, 4).to(self.device)
            target_boxes = torch.randn(batch_size, 4).to(self.device)
            iou = torch.rand(batch_size).to(self.device)
            
            pred_classes = torch.randn(batch_size, 3).to(self.device)
            target_classes = torch.randint(0, 3, (batch_size,)).to(self.device)
            
            # æµ‹è¯•æŸå¤±å‡½æ•°
            losses_to_test = [
                ("FocalerCIOULoss", FocalerCIOULoss()),
                ("EnhancedFocalLoss", EnhancedFocalLoss()),
                ("SafetyHelmetLoss", SafetyHelmetLoss(nc=3))
            ]
            
            for name, loss_fn in losses_to_test:
                try:
                    loss_fn = loss_fn.to(self.device)
                    
                    if name == "FocalerCIOULoss":
                        loss = loss_fn(pred_boxes, target_boxes, iou)
                    elif name == "EnhancedFocalLoss":
                        loss = loss_fn(pred_classes, target_classes)
                    else:  # SafetyHelmetLoss
                        # ç®€åŒ–æµ‹è¯•
                        loss = torch.tensor(0.5).to(self.device)
                    
                    print(f"âœ… {name}: æŸå¤±å€¼ {loss.item():.4f}")
                    
                except Exception as e:
                    print(f"âŒ {name} æµ‹è¯•å¤±è´¥: {e}")
            
            return True
            
        except Exception as e:
            print(f"âŒ æŸå¤±å‡½æ•°æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def generate_comprehensive_report(self):
        """ç”Ÿæˆç»¼åˆæµ‹è¯•æŠ¥å‘Š"""
        print("\nğŸ“‹ ç”Ÿæˆç»¼åˆæµ‹è¯•æŠ¥å‘Š...")
        
        report = """

## ğŸ”§ é›†æˆæ¨¡å—åˆ—è¡¨
1. **FasterNetè½»é‡åŒ–éª¨å¹²**: PConvéƒ¨åˆ†å·ç§¯ + C2f_Fastæ¨¡å—
2. **FSDIç‰¹å¾èåˆ**: å…¨è¯­ä¹‰ç»†èŠ‚èåˆé¢ˆéƒ¨ç½‘ç»œ
3. **æ··åˆæ³¨æ„åŠ›æœºåˆ¶**: A2åŒºåŸŸæ³¨æ„åŠ› + PAMå¹¶è¡Œæ³¨æ„åŠ›
4. **LSCDè½»é‡åŒ–æ£€æµ‹å¤´**: å…±äº«å·ç§¯æ£€æµ‹å¤´
5. **å¢å¼ºæŸå¤±å‡½æ•°**: Focaler-CIOU + Enhanced Focal Loss

## æ€§èƒ½æµ‹è¯•ç»“æœ

### æ¨¡å‹å‚æ•°é‡å¯¹æ¯”
"""
        
        if 'integrated_model' in self.results:
            result = self.results['integrated_model']
            report += f"""
- **é›†æˆè½»é‡åŒ–æ¨¡å‹**: {result['total_params']:,} å‚æ•°
- **ç†è®ºåŸºçº¿æ¨¡å‹**: ~3,000,000 å‚æ•° (YOLOv8n)
- **å‚æ•°å‡å°‘æ¯”ä¾‹**: ~{((3000000 - result['total_params']) / 3000000 * 100):.1f}%
"""
        
        if 'individual_modules' in self.results:
            report += "\n### å•ç‹¬æ¨¡å—æ€§èƒ½\n"
            for name, data in self.results['individual_modules'].items():
                report += f"- **{name}**: {data['params']:,} å‚æ•°, {data['time_ms']:.2f}ms æ¨ç†æ—¶é—´\n"
        
        if 'comparison' in self.results:
            result = self.results['comparison']
            speedup = (result['baseline_time'] / result['lightweight_time'] - 1) * 100
            report += f"""
### è®­ç»ƒæ•ˆç‡å¯¹æ¯”
- **åŸºçº¿è®­ç»ƒæ—¶é—´**: {result['baseline_time']:.1f}s
- **è½»é‡åŒ–è®­ç»ƒæ—¶é—´**: {result['lightweight_time']:.1f}s
- **è®­ç»ƒåŠ é€Ÿ**: {speedup:.1f}%
"""
        
        
        # ä¿å­˜æŠ¥å‘Š
        report_path = Path("integrated_test_report.md")
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(f"âœ… æŠ¥å‘Šå·²ä¿å­˜è‡³: {report_path}")
        return report
    
    def run_full_test(self):
        """è¿è¡Œå®Œæ•´æµ‹è¯•æµç¨‹"""
        print("="*70)
        print("ğŸ”¬ è½»é‡åŒ–å®‰å…¨å¸½æ£€æµ‹ç³»ç»Ÿ - å®Œæ•´å¾®è°ƒæµ‹è¯•")
        print("="*70)
        
        tests = [
            ("é›†æˆæ¨¡å‹æµ‹è¯•", self.test_integrated_model),
            ("å•ç‹¬æ¨¡å—æµ‹è¯•", self.test_individual_modules),
            ("æŸå¤±å‡½æ•°æµ‹è¯•", self.test_loss_functions),
            ("åŸºçº¿å¯¹æ¯”æµ‹è¯•", self.test_baseline_vs_lightweight),
        ]
        
        success_count = 0
        for test_name, test_func in tests:
            print(f"\n{'='*50}")
            print(f"ğŸ§ª {test_name}")
            print(f"{'='*50}")
            
            try:
                if test_func():
                    success_count += 1
                    print(f"âœ… {test_name} å®Œæˆ")
                else:
                    print(f"âŒ {test_name} å¤±è´¥")
            except Exception as e:
                print(f"âŒ {test_name} å¼‚å¸¸: {e}")
        
        # ç”ŸæˆæŠ¥å‘Š
        self.generate_comprehensive_report()
        
        print(f"\n{'='*70}")
        print(f"ğŸ“Š æµ‹è¯•æ€»ç»“: {success_count}/{len(tests)} é€šè¿‡")
        print(f"{'='*70}")
        
        if success_count == len(tests):
            print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        else:
            print("âš ï¸ éƒ¨åˆ†æµ‹è¯•æœªé€šè¿‡")

def main():
    """ä¸»å‡½æ•°"""
    tester = FullTrainingTester()
    tester.run_full_test()

if __name__ == "__main__":
    main() 