#!/usr/bin/env python3
import os
import torch
from pathlib import Path
from ultralytics import YOLO
import tempfile

def create_dummy_dataset():
    """åˆ›å»ºä¸€ä¸ªè™šæ‹Ÿçš„å°æ•°æ®é›†ç”¨äºå¿«é€Ÿæµ‹è¯•"""
    import yaml
    
    # åˆ›å»ºä¸´æ—¶ç›®å½•
    temp_dir = Path(tempfile.mkdtemp())
    
    # åˆ›å»ºç›®å½•ç»“æ„
    train_images = temp_dir / "train" / "images"
    train_labels = temp_dir / "train" / "labels"
    val_images = temp_dir / "val" / "images"
    val_labels = temp_dir / "val" / "labels"
    
    train_images.mkdir(parents=True, exist_ok=True)
    train_labels.mkdir(parents=True, exist_ok=True)
    val_images.mkdir(parents=True, exist_ok=True)
    val_labels.mkdir(parents=True, exist_ok=True)
    
    # åˆ›å»ºè™šæ‹Ÿå›¾åƒå’Œæ ‡ç­¾
    import numpy as np
    from PIL import Image
    
    for i in range(5):  # 5å¼ è®­ç»ƒå›¾åƒ
        # åˆ›å»ºè™šæ‹Ÿå›¾åƒ (640x640)
        img = Image.fromarray(np.random.randint(0, 255, (640, 640, 3), dtype=np.uint8))
        img.save(train_images / f"img_{i}.jpg")
        
        # åˆ›å»ºè™šæ‹Ÿæ ‡ç­¾ (YOLOæ ¼å¼)
        with open(train_labels / f"img_{i}.txt", 'w') as f:
            # class_id center_x center_y width height
            f.write("0 0.5 0.5 0.2 0.2\n")  # person
            f.write("1 0.3 0.3 0.1 0.1\n")  # helmet
    
    for i in range(2):  # 2å¼ éªŒè¯å›¾åƒ
        img = Image.fromarray(np.random.randint(0, 255, (640, 640, 3), dtype=np.uint8))
        img.save(val_images / f"val_{i}.jpg")
        
        with open(val_labels / f"val_{i}.txt", 'w') as f:
            f.write("0 0.4 0.4 0.2 0.2\n")
            f.write("2 0.6 0.6 0.1 0.1\n")  # no_helmet
    
    # åˆ›å»ºæ•°æ®é›†é…ç½®æ–‡ä»¶
    config_data = {
        'train': str(train_images),
        'val': str(val_images),
        'nc': 3,
        'names': ['person', 'helmet', 'no_helmet']
    }
    
    config_path = temp_dir / "dataset.yaml"
    with open(config_path, 'w') as f:
        yaml.dump(config_data, f)
    
    print(f"âœ… åˆ›å»ºè™šæ‹Ÿæ•°æ®é›†: {temp_dir}")
    return str(config_path)

def test_baseline_training():
    """æµ‹è¯•åŸºçº¿YOLOv8æ¨¡å‹å¿«é€Ÿè®­ç»ƒ"""
    print("ğŸ”„ å¼€å§‹åŸºçº¿æ¨¡å‹å¾®è°ƒæµ‹è¯•...")
    
    try:
        # åˆ›å»ºè™šæ‹Ÿæ•°æ®é›†
        dataset_config = create_dummy_dataset()
        
        # åˆå§‹åŒ–YOLOv8næ¨¡å‹
        model = YOLO('yolov8n.pt')
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
        
        # æç®€è®­ç»ƒé…ç½®
        train_args = {
            'data': dataset_config,
            'epochs': 2,  # åªè®­ç»ƒ2ä¸ªepoch
            'batch': 2,   # å°æ‰¹æ¬¡
            'imgsz': 320, # å°å›¾åƒå°ºå¯¸
            'patience': 1,
            'save': False,
            'plots': False,
            'val': True,
            'verbose': True,
            'device': 'cpu'  # å¼ºåˆ¶ä½¿ç”¨CPU
        }
        
        print("ğŸš€ å¼€å§‹å¾®è°ƒè®­ç»ƒ...")
        results = model.train(**train_args)
        
        print("âœ… è®­ç»ƒå®Œæˆ!")
        print(f"æœ€ç»ˆmAP50: {results.results_dict.get('metrics/mAP50(B)', 'N/A')}")
        
        # æµ‹è¯•æ¨ç†
        print("\nğŸ§ª æµ‹è¯•æ¨ç†...")
        test_img = "https://ultralytics.com/images/bus.jpg"
        results = model(test_img)
        print("âœ… æ¨ç†æµ‹è¯•æˆåŠŸ")
        
        return True
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_lightweight_modules():
    """æµ‹è¯•è½»é‡åŒ–æ¨¡å—çš„é›†æˆ"""
    print("\nğŸ”§ æµ‹è¯•è½»é‡åŒ–æ¨¡å—é›†æˆ...")
    
    try:
        from modules.fasternet import FasterNetBlock, C2f_Fast
        from modules.attention import A2_Attention
        from modules.losses import FocalerCIOULoss
        
        # åˆ›å»ºä¸€ä¸ªç®€å•çš„è½»é‡åŒ–ç½‘ç»œ
        class LightweightNet(torch.nn.Module):
            def __init__(self):
                super().__init__()
                self.fasternet = FasterNetBlock(256, 256)
                self.attention = A2_Attention(256)
                self.c2f_fast = C2f_Fast(256, 256, n=2)
                
            def forward(self, x):
                x = self.fasternet(x)
                x = self.attention(x)
                x = self.c2f_fast(x)
                return x
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        net = LightweightNet()
        test_input = torch.randn(1, 256, 32, 32)
        output = net(test_input)
        
        print(f"âœ… è½»é‡åŒ–ç½‘ç»œæµ‹è¯•: {test_input.shape} -> {output.shape}")
        
        # æµ‹è¯•æŸå¤±å‡½æ•°
        loss_fn = FocalerCIOULoss()
        print("âœ… æŸå¤±å‡½æ•°åˆå§‹åŒ–æˆåŠŸ")
        
        return True
        
    except Exception as e:
        print(f"âŒ è½»é‡åŒ–æ¨¡å—æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    print("="*60)
    print("ğŸ§ª è½»é‡åŒ–å®‰å…¨å¸½æ£€æµ‹ç³»ç»Ÿ - å¿«é€Ÿå¾®è°ƒæµ‹è¯•")
    print("="*60)
    
    # æµ‹è¯•1: è½»é‡åŒ–æ¨¡å—
    success1 = test_lightweight_modules()
    
    # æµ‹è¯•2: åŸºçº¿è®­ç»ƒ
    success2 = test_baseline_training()
    
    print("\n" + "="*60)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»")
    print("="*60)
    print(f"è½»é‡åŒ–æ¨¡å—æµ‹è¯•: {'âœ… é€šè¿‡' if success1 else 'âŒ å¤±è´¥'}")
    print(f"åŸºçº¿è®­ç»ƒæµ‹è¯•: {'âœ… é€šè¿‡' if success2 else 'âŒ å¤±è´¥'}")
    
    if success1 and success2:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç³»ç»Ÿè¿è¡Œæ­£å¸¸ã€‚")
        print("ğŸ’¡ å¯ä»¥å¼€å§‹æ­£å¼çš„æ¨¡å‹è®­ç»ƒå’Œä¼˜åŒ–å·¥ä½œã€‚")
    else:
        print("\nâš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç¯å¢ƒé…ç½®ã€‚")
    
    print("="*60)

if __name__ == "__main__":
    main() 