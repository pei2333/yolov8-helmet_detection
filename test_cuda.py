#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
CUDAè¯Šæ–­è„šæœ¬
ç”¨äºæ£€æŸ¥PyTorchçš„CUDAæ”¯æŒæƒ…å†µ
"""

import torch
import sys
import os

def test_cuda():
    """æµ‹è¯•CUDAæ”¯æŒæƒ…å†µ"""
    print("=" * 60)
    print("ğŸ” CUDAè¯Šæ–­æŠ¥å‘Š")
    print("=" * 60)
    
    # 1. åŸºæœ¬ä¿¡æ¯
    print(f"Pythonç‰ˆæœ¬: {sys.version}")
    print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
    print(f"PyTorchæ„å»ºä¿¡æ¯: {torch.version.cuda}")
    
    # 2. CUDAå¯ç”¨æ€§
    print(f"\nğŸ“Š CUDAæ”¯æŒæƒ…å†µ:")
    print(f"torch.cuda.is_available(): {torch.cuda.is_available()}")
    
    if torch.cuda.is_available():
        print(f"CUDAç‰ˆæœ¬: {torch.version.cuda}")
        print(f"GPUæ•°é‡: {torch.cuda.device_count()}")
        print(f"å½“å‰è®¾å¤‡: {torch.cuda.current_device()}")
        
        # 3. GPUä¿¡æ¯
        print(f"\nğŸ–¥ï¸ GPUè¯¦ç»†ä¿¡æ¯:")
        for i in range(torch.cuda.device_count()):
            print(f"GPU {i}: {torch.cuda.get_device_name(i)}")
            print(f"  å†…å­˜: {torch.cuda.get_device_properties(i).total_memory / 1024**3:.1f} GB")
            print(f"  è®¡ç®—èƒ½åŠ›: {torch.cuda.get_device_properties(i).major}.{torch.cuda.get_device_properties(i).minor}")
        
        # 4. æµ‹è¯•CUDAå¼ é‡
        print(f"\nğŸ§ª CUDAå¼ é‡æµ‹è¯•:")
        try:
            x = torch.randn(3, 3).cuda()
            y = torch.randn(3, 3).cuda()
            z = torch.mm(x, y)
            print("âœ… CUDAå¼ é‡è¿ç®—æµ‹è¯•é€šè¿‡")
            print(f"   ç»“æœå½¢çŠ¶: {z.shape}")
            print(f"   è®¾å¤‡: {z.device}")
        except Exception as e:
            print(f"âŒ CUDAå¼ é‡è¿ç®—æµ‹è¯•å¤±è´¥: {e}")
        
        # 5. å†…å­˜ä¿¡æ¯
        print(f"\nğŸ’¾ GPUå†…å­˜ä¿¡æ¯:")
        print(f"å·²åˆ†é…: {torch.cuda.memory_allocated() / 1024**2:.1f} MB")
        print(f"å·²ç¼“å­˜: {torch.cuda.memory_reserved() / 1024**2:.1f} MB")
        print(f"æ€»å†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**2:.1f} MB")
        
    else:
        print("âŒ CUDAä¸å¯ç”¨")
        
        # æ£€æŸ¥å¯èƒ½çš„åŸå› 
        print(f"\nğŸ” å¯èƒ½çš„åŸå› :")
        print("1. PyTorchå®‰è£…çš„æ˜¯CPUç‰ˆæœ¬")
        print("2. CUDAé©±åŠ¨ç¨‹åºç‰ˆæœ¬ä¸åŒ¹é…")
        print("3. ç¯å¢ƒå˜é‡è®¾ç½®é—®é¢˜")
        
        # æ£€æŸ¥ç¯å¢ƒå˜é‡
        print(f"\nğŸŒ ç¯å¢ƒå˜é‡æ£€æŸ¥:")
        cuda_home = os.environ.get('CUDA_HOME')
        cuda_path = os.environ.get('CUDA_PATH')
        print(f"CUDA_HOME: {cuda_home}")
        print(f"CUDA_PATH: {cuda_path}")
    
    # 6. è®¾å¤‡é€‰æ‹©æµ‹è¯•
    print(f"\nğŸ¯ è®¾å¤‡é€‰æ‹©æµ‹è¯•:")
    try:
        # æµ‹è¯•autoè®¾å¤‡é€‰æ‹©
        device = torch.device('auto' if torch.cuda.is_available() else 'cpu')
        print(f"è‡ªåŠ¨è®¾å¤‡é€‰æ‹©: {device}")
        
        # æµ‹è¯•CUDAè®¾å¤‡é€‰æ‹©
        if torch.cuda.is_available():
            device = torch.device('cuda:0')
            print(f"CUDAè®¾å¤‡é€‰æ‹©: {device}")
            
            # æµ‹è¯•å¼ é‡åˆ°CUDA
            x = torch.randn(2, 2)
            x_cuda = x.to(device)
            print(f"å¼ é‡è®¾å¤‡è½¬æ¢: {x.device} -> {x_cuda.device}")
            
    except Exception as e:
        print(f"âŒ è®¾å¤‡é€‰æ‹©æµ‹è¯•å¤±è´¥: {e}")
    
    print("\n" + "=" * 60)
    print("è¯Šæ–­å®Œæˆ")
    print("=" * 60)

if __name__ == '__main__':
    test_cuda() 